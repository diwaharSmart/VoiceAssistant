<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>High-Quality PCM Audio Streaming</title>
    <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/bootstrap-icons/1.5.0/font/bootstrap-icons.min.css" rel="stylesheet">
    <style>
        body, html {
            height: 100%;
            width: 100%;
            display: flex;
            align-items: center;
            justify-content: center;
            background-color: green;
            transition: background-color 0.3s ease;
        }
        .call-icon {
            font-size: 100px;
            color: white;
            cursor: pointer;
        }
    </style>
</head>
<body>

<div class="text-center">
    <i id="call-icon" class="bi bi-telephone-fill call-icon"></i>
</div>
{{ room_name|json_script:"room-name" }}
<script>
    let audioContext;
    let ws;
    let processor;
    let source;
    let recording = false;
    let audioSource;
    const roomName = JSON.parse(document.getElementById('room-name').textContent);

    document.getElementById('call-icon').addEventListener('click', async () => {
        if (!recording) {
            ws = new WebSocket('ws://'
            + window.location.host
            + '/ws/realtime/'
            + roomName
            + '/');
            ws.onopen = () => {
                console.log("WebSocket connection opened");
                document.body.style.backgroundColor = 'red';
                recording = true;
            }
            ws.onmessage = async (event) => {
                const message = JSON.parse(event.data);

                if (message.command === "stop_audio" && audioSource) {
                    audioSource.stop();
                } else if (message.command === "play_audio" && message.audio_bytes) {
                    const audioData = Uint8Array.from(atob(message.audio_bytes), c => c.charCodeAt(0));
                    const audioBuffer = await audioContext.decodeAudioData(audioData.buffer);

                    if (audioSource) {
                        audioSource.stop();
                    }

                    audioSource = audioContext.createBufferSource();
                    audioSource.buffer = audioBuffer;

                    // Create a silent gain node for playback audio to avoid feedback
                    const playbackGain = audioContext.createGain();
                    playbackGain.gain.value = 1; // Control volume if needed, or set to 1 for normal playback

                    // Connect audio source through silent gain to destination
                    audioSource.connect(playbackGain).connect(audioContext.destination);
                    audioSource.start();
                }
            };
            ws.onerror = () => {
              document.body.style.backgroundColor = 'green';
              if (processor) processor.disconnect();
              if (source) source.disconnect();
              recording = false;
            }
            ws.onclose = () => {
                document.body.style.backgroundColor = 'green';
                if (processor) processor.disconnect();
                if (source) source.disconnect();
                recording = false;
            }

            const stream = await navigator.mediaDevices.getUserMedia({
                audio: {
                    echoCancellation: { ideal: true },
                    noiseSuppression: { ideal: true },
                    autoGainControl: true,
                    sampleRate: 16000,
                    channelCount: 1
                }
            });

            // Set up audio context for PCM processing
            audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
            source = audioContext.createMediaStreamSource(stream);
            processor = audioContext.createScriptProcessor(4096, 1, 1);
            // Create a silent gain node
            const silentGain = audioContext.createGain();
            silentGain.gain.value = 0; // Mute output to avoid feedback

            // Connect processor to silent gain to keep audio flow active
            processor.connect(silentGain);
            silentGain.connect(audioContext.destination)
            // PCM Processing
            processor.onaudioprocess = (event) => {
                let inputBuffer = event.inputBuffer.getChannelData(0); // Get audio data from the first channel
                let buffer = new Int16Array(inputBuffer.length);

                // Convert from Float32 to Int16 PCM
                for (let i = 0; i < inputBuffer.length; i++) {
                    buffer[i] = Math.max(-1, Math.min(1, inputBuffer[i])) * 32767;
                }

                // Send PCM data over WebSocket
                if (ws.readyState === WebSocket.OPEN) {
                    ws.send(buffer);
                    console.log("Sent PCM data chunk");
                }
            };

            // Connect nodes
            source.connect(processor);
            // processor.connect(audioContext.destination);
        } else {
            // Stop recording
            if (processor) processor.disconnect();
            if (source) source.disconnect();
            if (ws) ws.close();

            document.body.style.backgroundColor = 'green';
            recording = false;
        }
    });
</script>

</body>
</html>